# TTS
The basic idea of this method is to design three predictors based on the acoustic structure to fully express the speech features. The timbre predictor obtains the time-frequency feature through the time-frequency analysis of the spectrogram, which reflects the speaker's timbre. The loudness predictor and the tone predictor obtain the energy feature and the pitch feature from the amplitude and frequency of the spectrogram, which represent the speaker's loudness and tone. Extensive experiments show that our model can effectively synthesize high-quality speech that is closer to the speaker's speech features than other state-of-the-art methods.
![pipeline11](https://github.com/user-attachments/assets/0fb01682-6d84-4f85-999c-c2dac0828fcf)

# Demo
https://github.com/user-attachments/assets/45404955-2f89-41e2-8081-29db55d393af



# Audio Samples
Audio [samples](demo) generated by this implementation can be found above.

# Datasets
LJSpeech: a single-speaker English dataset consists of 13100 short audio clips of a female speaker reading passages from 7 non-fiction books, approximately 24 hours in total.  
LibriTTS: a multi-speaker English dataset containing 585 hours of speech by 2456 speakers.
